{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup","metadata":{}},{"cell_type":"code","source":"from IPython.display import clear_output as cls","metadata":{"papermill":{"duration":0.030231,"end_time":"2023-06-11T18:37:09.437780","exception":false,"start_time":"2023-06-11T18:37:09.407549","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-06-23T04:19:19.877068Z","iopub.execute_input":"2023-06-23T04:19:19.877642Z","iopub.status.idle":"2023-06-23T04:19:19.906673Z","shell.execute_reply.started":"2023-06-23T04:19:19.877606Z","shell.execute_reply":"2023-06-23T04:19:19.905866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data no split\n# https://drive.google.com/file/d/1ey1O_1cZEnqP8s4mHjCvT8vpfAOlvP9L/view?usp=sharing\n\n# data with split - train val test\n# https://drive.google.com/file/d/14Rjq65k_qzXDje0atzyDl9WziapGaifp/view?usp=sharing\n\n# data with split and converted - train val test\n# https://drive.google.com/file/d/10eYtkh6bTWNwH_--xZtU8IxB5cZPVc3O/view?usp=drive_link\n\n# data with split and converted clean - train val test\n# https://drive.google.com/file/d/184s1XY7oZ2ukeMUzhMjH-MEXROGuGCk3/view?usp=drive_link\n\n# data with split, converted clean, and augmented\n# https://drive.google.com/file/d/1bydjm-fAYVwa-1J7J5riWVEWc2OVM3BZ/view?usp=drive_link\n\n!pip install gdown\n\n!rm -r dataset\n# !gdown \"https://drive.google.com/uc?id=184s1XY7oZ2ukeMUzhMjH-MEXROGuGCk3\" -O dataset.zip\n!gdown \"https://drive.google.com/uc?id=1bydjm-fAYVwa-1J7J5riWVEWc2OVM3BZ\" -O dataset.zip\n!unzip dataset.zip -d dataset\n\ncls()","metadata":{"papermill":{"duration":30.231124,"end_time":"2023-06-11T18:37:39.683567","exception":false,"start_time":"2023-06-11T18:37:09.452443","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-06-23T04:19:19.908039Z","iopub.execute_input":"2023-06-23T04:19:19.908481Z","iopub.status.idle":"2023-06-23T04:19:51.655493Z","shell.execute_reply.started":"2023-06-23T04:19:19.908448Z","shell.execute_reply":"2023-06-23T04:19:51.654505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# common\nimport os\nimport numpy as np\nimport tensorflow as tf\nimport typing\nfrom tensorflow import keras\nfrom typing import Tuple, List\nfrom tqdm import tqdm\nfrom glob import glob\nfrom datetime import datetime\n\n# preprocessing\nfrom tensorflow import image as tfi\n\n# architecture\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.applications import Xception, InceptionV3, VGG16\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Dense\n\n# visualization\nimport pandas as pd\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tensorflow.keras.utils import plot_model\n\n# Model Training\n# from tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom sklearn.metrics import confusion_matrix, classification_report\n\n# CSV Callback\nfrom tensorflow.keras.callbacks import CSVLogger\n\ncls()","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":9.776515,"end_time":"2023-06-11T18:37:49.474659","exception":false,"start_time":"2023-06-11T18:37:39.698144","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-06-23T04:19:51.656834Z","iopub.execute_input":"2023-06-23T04:19:51.657679Z","iopub.status.idle":"2023-06-23T04:19:59.969504Z","shell.execute_reply.started":"2023-06-23T04:19:51.657634Z","shell.execute_reply":"2023-06-23T04:19:59.968842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_dir = '/kaggle/working/dataset/clean_data_splitted_convert/train/'\n# val_dir = '/kaggle/working/dataset/clean_data_splitted_convert/val/'\n# test_dir = '/kaggle/working/dataset/clean_data_splitted_convert/test/'\n\ntrain_dir = '/kaggle/working/dataset/clean_data_splitted_convert_augment/train/'\nval_dir = '/kaggle/working/dataset/clean_data_splitted_convert_augment/val/'\ntest_dir = '/kaggle/working/dataset/clean_data_splitted_convert_augment/test/'","metadata":{"papermill":{"duration":0.021747,"end_time":"2023-06-11T18:37:49.512003","exception":false,"start_time":"2023-06-11T18:37:49.490256","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-06-23T04:19:59.971027Z","iopub.execute_input":"2023-06-23T04:19:59.971830Z","iopub.status.idle":"2023-06-23T04:19:59.976211Z","shell.execute_reply.started":"2023-06-23T04:19:59.971804Z","shell.execute_reply":"2023-06-23T04:19:59.974811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Constants\n\nIMAGE_SIZE = 300\nBATCH_SIZE = 32\nEPOCHS = 50\n# EPOCHS = 1\n\n\n# LEARNING_RATE = 1e-4\nLEARNING_RATE = 1e-3\n\n\nLOSS = tf.keras.losses.SparseCategoricalCrossentropy()\nMETRICS = ['accuracy']\n# OPTIMIZER = Adam(learning_rate=LEARNING_RATE)\n# OPTIMIZER = SGD(learning_rate=LEARNING_RATE)\n\n# callback\nEARLYSTOP_PATIENCE = 5\n\n\n# Random Seed\nrandom_seed = 42 # set random seed for reproducibility\ntf.random.set_seed(random_seed) # set random seed for TensorFlow\nnp.random.seed(random_seed) # set random seed for NumPy","metadata":{"papermill":{"duration":0.023761,"end_time":"2023-06-11T18:37:49.550249","exception":false,"start_time":"2023-06-11T18:37:49.526488","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-06-23T04:19:59.977110Z","iopub.execute_input":"2023-06-23T04:19:59.977344Z","iopub.status.idle":"2023-06-23T04:19:59.990395Z","shell.execute_reply.started":"2023-06-23T04:19:59.977324Z","shell.execute_reply":"2023-06-23T04:19:59.989494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Collect the class names\nclass_names = sorted(os.listdir(train_dir))\nn_classes = len(class_names)","metadata":{"execution":{"iopub.status.busy":"2023-06-23T04:19:59.991591Z","iopub.execute_input":"2023-06-23T04:19:59.992063Z","iopub.status.idle":"2023-06-23T04:20:00.003077Z","shell.execute_reply.started":"2023-06-23T04:19:59.992039Z","shell.execute_reply":"2023-06-23T04:20:00.002161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Functions","metadata":{}},{"cell_type":"code","source":"def load_image(image_path: str) -> tf.Tensor:\n    \n    '''\n    The task of the function is to load the image present in the specified given image path. Loading the image the function also performed some \n    preprocessing steps such as resizing and normalization.\n    \n    Argument:\n        image_path(str) : This is a string which represents the location of the image file to be loaded.\n        \n    Returns:\n        image(tf.Tensor) : This is the image which is loaded from the given image part in the form of a tensor.\n    '''\n    \n    # Check if image path exists\n    assert os.path.exists(image_path), f'Invalid image path: {image_path}'\n    \n    # Read the image file\n    image = tf.io.read_file(image_path)\n    \n    # Load the image\n    try:\n        image = tfi.decode_jpeg(image, channels=3)\n    except:\n        image = tfi.decode_png(image, channels=3)\n    \n    # Change the image data type\n    image = tfi.convert_image_dtype(image, tf.float32)\n    \n    # Resize the Image\n    image = tfi.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n    \n    # Rescale pixel values to be in the range [0, 1]\n    image = tf.image.per_image_standardization(image)\n    \n    # Convert image data type to tf.float32\n    image = tf.cast(image, tf.float32)\n    \n    return image","metadata":{"execution":{"iopub.status.busy":"2023-06-23T04:20:00.004155Z","iopub.execute_input":"2023-06-23T04:20:00.004474Z","iopub.status.idle":"2023-06-23T04:20:00.013255Z","shell.execute_reply.started":"2023-06-23T04:20:00.004446Z","shell.execute_reply":"2023-06-23T04:20:00.012405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_dataset(root_path: str, class_names: list, batch_size: int = 32, buffer_size: int = 1000) -> Tuple[np.ndarray, np.ndarray]:\n    '''\n    Load and preprocess images from the given root path and return them as numpy arrays.\n\n    Args:\n        root_path (str): Path to the root directory where all the subdirectories (class names) are present.\n        class_names (list): List of the names of all the subdirectories (class names).\n        batch_size (int): Batch size of the final dataset. Defaults to 32.\n        buffer_size (int): Buffer size to use when shuffling the data. Defaults to 1000.\n\n    Returns:\n        Two numpy arrays, one containing the images and the other containing their respective labels.\n    '''\n\n    # Collect total number of data samples\n    n_samples = sum([len(os.listdir(os.path.join(root_path, name))) for name in class_names])\n\n    # Create arrays to store images and labels\n    images = np.empty(shape=(n_samples, IMAGE_SIZE, IMAGE_SIZE, 3), dtype=np.float32)\n    labels = np.empty(shape=(n_samples, 1), dtype=np.int32)\n\n    errors = []\n    \n    # Loop over all the image file paths, load and store the images with respective labels\n    n_image = 0\n    for class_name in tqdm(class_names, desc=\"Loading\"):\n        class_path = os.path.join(root_path, class_name)\n        for file_path in glob(os.path.join(class_path, \"*\")):\n            # Load the image\n            try:\n                image = load_image(file_path)\n                \n                # Assign label\n                label = class_names.index(class_name)\n\n                # Store the image and the respective label\n                images[n_image] = image\n                labels[n_image] = label\n\n                # Increment the number of images processed\n                n_image += 1\n                \n            except:\n                errors.append(file_path)\n            \n    # Shuffle the data\n    indices = np.random.permutation(n_samples)\n    images = images[indices]\n    labels = labels[indices]\n    \n    print('num of errors:', len(errors))\n\n    return images, labels, errors","metadata":{"execution":{"iopub.status.busy":"2023-06-23T04:20:00.014411Z","iopub.execute_input":"2023-06-23T04:20:00.015193Z","iopub.status.idle":"2023-06-23T04:20:00.024363Z","shell.execute_reply.started":"2023-06-23T04:20:00.015164Z","shell.execute_reply":"2023-06-23T04:20:00.023822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_and_preprocess_image(image, label):\n    # Resize the image to the desired size\n    image = tf.image.resize(image, [IMAGE_SIZE, IMAGE_SIZE])\n    \n    # Rescale pixel values to be in the range [0, 1]\n    image = tf.image.per_image_standardization(image)\n    \n#     # Convert image data type to tf.float32\n#     image = tf.cast(image, tf.float32)\n    \n    return image, label","metadata":{"execution":{"iopub.status.busy":"2023-06-23T04:20:00.027488Z","iopub.execute_input":"2023-06-23T04:20:00.028302Z","iopub.status.idle":"2023-06-23T04:20:00.038088Z","shell.execute_reply.started":"2023-06-23T04:20:00.028280Z","shell.execute_reply":"2023-06-23T04:20:00.037530Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_images(dataset: tf.data.Dataset, n_rows: int = 5, n_cols: int = 4, class_names=class_names, figsize=(20, 20), model=None, check=False):\n    \"\"\"\n    Plots a grid of images and their corresponding labels from a tf.data.Dataset object.\n\n    Args:\n        dataset (tf.data.Dataset): A TensorFlow dataset object containing the images and labels to plot.\n        n_rows (int): Number of rows in the plot grid. Default is 5.\n        n_cols (int): Number of columns in the plot grid. Default is 4.\n        class_names (list): A list of strings mapping the integer labels to their corresponding class names. Default is None.\n        figsize (tuple): A tuple specifying the size of the figure. Default is (20, 20).\n        model (tf.keras.Model): A trained TensorFlow model to make predictions on the images. Default is None.\n        check (bool): If True and a model is provided, only incorrectly predicted images will be plotted. Default is False.\n    \"\"\"\n    \n    # Create a figure to display the images\n    fig = plt.figure(figsize=figsize)\n    \n    # Initialize image counter\n    image_count = 0\n    \n    # Loop over all batches in dataset\n    for images, labels in dataset:\n        \n        # Loop over all images in batch\n        for i in range(images.shape[0]):\n            \n            label = int(labels[i].numpy())\n            title = \"true: \"+class_names[label]\n\n            if model:\n                pred = model.predict(images[i][np.newaxis])\n\n                if check:\n                    if label == np.argmax(pred):\n                        continue\n\n                pred_label = f\"Pred: {np.argmax(pred)}\"\n                pred_percentage = f\" ({np.max(pred) * 100:.2f}%)\"\n                if class_names:\n                    pred_label += f\" ({class_names[np.argmax(pred)]})\"\n                title += f\"\\n{pred_label} {pred_percentage}\"\n\n            # Create a subplot for each image\n            ax = fig.add_subplot(n_rows, n_cols, image_count+1)    \n\n            # Plot the image\n            ax.imshow(images[i].numpy().astype(\"uint8\"))\n\n            # Set the title to the corresponding label\n            ax.set_title(title)\n\n            # Remove the axis ticks\n            ax.set_xticks([])\n            ax.set_yticks([])\n            \n            # Increment image counter\n            image_count += 1\n            \n            # Check if maximum number of images has been reached\n            if image_count >= n_rows * n_cols:\n                break\n        \n        # Check if maximum number of images has been reached\n        if image_count >= n_rows * n_cols:\n            break\n    \n    # Show the plot\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-06-23T04:20:00.039259Z","iopub.execute_input":"2023-06-23T04:20:00.039850Z","iopub.status.idle":"2023-06-23T04:20:00.050257Z","shell.execute_reply.started":"2023-06-23T04:20:00.039801Z","shell.execute_reply":"2023-06-23T04:20:00.049495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def timer(start_time: datetime = None) -> \"typing.Union[datetime.datetime, str]\":\n    \"\"\"\n    Measures the time elapsed from a given start time.\n\n    If no start time is provided, returns the current time. If a start time is provided, returns a formatted string\n    representing the time elapsed from the start time to the current time.\n\n    Args:\n        start_time (datetime.datetime, optional): The start time to measure elapsed time from, or None to get the current time. Defaults to None.\n\n    Returns:\n        Union[datetime.datetime, str]: The current time if no start time is provided, or a formatted string representing the elapsed time.\n    \"\"\"\n    if not start_time:\n        start_time = datetime.now()\n        return start_time\n    elif start_time:\n        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n        tmin, tsec = divmod(temp_sec, 60)\n        return \"%i hours %i minutes and %s seconds.\" % (\n            thour,\n            tmin,\n            round(tsec, 2),\n        )","metadata":{"execution":{"iopub.status.busy":"2023-06-23T04:20:00.051339Z","iopub.execute_input":"2023-06-23T04:20:00.052120Z","iopub.status.idle":"2023-06-23T04:20:00.065609Z","shell.execute_reply.started":"2023-06-23T04:20:00.052092Z","shell.execute_reply":"2023-06-23T04:20:00.065056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_history(history, test_loss, test_acc, model_name):\n    # Collect the history of the training run\n    history_plot = pd.DataFrame(history.history)\n    \n    # Create a figure to display the model's performance\n    plt.figure(figsize=(20, 5))\n\n    # Plot the loss curve in the first subplot\n    plt.subplot(1, 2, 1)\n    plt.title(f\"{model_name} - Loss Curve\")\n    plt.plot(history_plot['loss'], label=\"Training Loss\")\n    plt.plot(history_plot['val_loss'], label=\"Validation Loss\")\n\n    # Horizontal line to show the testing performance\n    plt.axhline(y=test_loss, label=\"Test Loss\", linestyle='--', color='green')\n\n    # Set the x- and y-labels, and the x- and y-limits\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Cross Entropy Loss\")\n    # plt.ylim([0, 0.4])\n\n    # Show the legend and grid\n    plt.legend()\n    plt.grid()\n\n    # Plot the accuracy curve in the second subplot\n    plt.subplot(1, 2, 2)\n    plt.title(f\"{model_name} - Accuracy Curve\")\n    plt.plot(history_plot['accuracy'], label=\"Training Accuracy\")\n    plt.plot(history_plot['val_accuracy'], label=\"Validation Accuracy\")\n\n    # Horizontal line to show the testing performance\n    plt.axhline(y=test_acc, label=\"Test Accuracy\", linestyle='--', color='green')\n\n    # Set the x- and y-labels, and the x- and y-limits\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Accuracy\")\n    # plt.ylim([0.85, 1])\n\n    # Show the legend and grid\n    plt.legend()\n    plt.grid()\n\n    # Display the plot\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-06-23T04:20:00.066533Z","iopub.execute_input":"2023-06-23T04:20:00.066751Z","iopub.status.idle":"2023-06-23T04:20:00.079747Z","shell.execute_reply.started":"2023-06-23T04:20:00.066732Z","shell.execute_reply":"2023-06-23T04:20:00.078989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_confusion_m(y_true, y_pred, class_names=None, figsize=(15,15)):\n    cm = confusion_matrix(y_true, y_pred)\n    plt.figure(figsize=figsize)\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-06-23T04:20:00.080591Z","iopub.execute_input":"2023-06-23T04:20:00.080800Z","iopub.status.idle":"2023-06-23T04:20:00.094206Z","shell.execute_reply.started":"2023-06-23T04:20:00.080781Z","shell.execute_reply":"2023-06-23T04:20:00.093488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Prep","metadata":{}},{"cell_type":"code","source":"# Show\nprint(f\"Total number of classes in train: {n_classes}\")\nprint(f\"Classes: {class_names}\")","metadata":{"execution":{"iopub.status.busy":"2023-06-23T04:20:00.094985Z","iopub.execute_input":"2023-06-23T04:20:00.095203Z","iopub.status.idle":"2023-06-23T04:20:00.103979Z","shell.execute_reply.started":"2023-06-23T04:20:00.095184Z","shell.execute_reply":"2023-06-23T04:20:00.103471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Load the training dataset\n# X_train, y_train, err_train = load_dataset(root_path = train_dir, class_names = class_names)\n\n# # # Load the validation dataset\n# X_valid, y_valid, err_val = load_dataset(root_path = val_dir, class_names = class_names)\n\n# # Load the testing dataset\n# X_test, y_test, err_test = load_dataset(root_path = test_dir, class_names = class_names)","metadata":{"execution":{"iopub.status.busy":"2023-06-23T04:20:00.104925Z","iopub.execute_input":"2023-06-23T04:20:00.105330Z","iopub.status.idle":"2023-06-23T04:20:00.113600Z","shell.execute_reply.started":"2023-06-23T04:20:00.105297Z","shell.execute_reply":"2023-06-23T04:20:00.113052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print('train err:', err_train)\n# print('val err:', err_val)\n# print('test err:', err_test)","metadata":{"execution":{"iopub.status.busy":"2023-06-23T04:20:00.114436Z","iopub.execute_input":"2023-06-23T04:20:00.114801Z","iopub.status.idle":"2023-06-23T04:20:00.126929Z","shell.execute_reply.started":"2023-06-23T04:20:00.114780Z","shell.execute_reply":"2023-06-23T04:20:00.126109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# del X_train, y_train, X_valid, y_valid, X_test, y_test","metadata":{"execution":{"iopub.status.busy":"2023-06-23T04:20:00.127831Z","iopub.execute_input":"2023-06-23T04:20:00.128205Z","iopub.status.idle":"2023-06-23T04:20:00.136908Z","shell.execute_reply.started":"2023-06-23T04:20:00.128182Z","shell.execute_reply":"2023-06-23T04:20:00.136360Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Drop corrupted data","metadata":{}},{"cell_type":"code","source":"try:\n    corrupted = '/kaggle/working/dataset/clean_data_splitted_convert/train/ra/000021.jpg'\n    os.remove(corrupted)\nexcept:\n    print('Somethings wong!')","metadata":{"execution":{"iopub.status.busy":"2023-06-23T04:20:00.137833Z","iopub.execute_input":"2023-06-23T04:20:00.138247Z","iopub.status.idle":"2023-06-23T04:20:00.147167Z","shell.execute_reply.started":"2023-06-23T04:20:00.138226Z","shell.execute_reply":"2023-06-23T04:20:00.146344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Dataset","metadata":{}},{"cell_type":"code","source":"# del train_ds, val_ds, test_ds\n# del train_ds_mapped, val_ds_mapped, test_ds_mapped\n\n# Create a dataset from the data directory\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(train_dir, \n#                                                                labels='inferred', \n#                                                                label_mode='int',\n#                                                                image_size=(IMAGE_SIZE, IMAGE_SIZE),\n                                                               batch_size=BATCH_SIZE\n                                                              )\n\nval_ds = tf.keras.preprocessing.image_dataset_from_directory(val_dir,\n#                                                              labels='inferred', \n#                                                              label_mode='int',\n#                                                              image_size=(IMAGE_SIZE, IMAGE_SIZE),\n                                                             batch_size=BATCH_SIZE\n                                                              )\n\ntest_ds = tf.keras.preprocessing.image_dataset_from_directory(test_dir, \n#                                                                labels='inferred', \n#                                                                label_mode='int',\n#                                                                image_size=(IMAGE_SIZE, IMAGE_SIZE),\n                                                               batch_size=BATCH_SIZE\n                                                              )","metadata":{"execution":{"iopub.status.busy":"2023-06-23T04:20:00.147922Z","iopub.execute_input":"2023-06-23T04:20:00.148146Z","iopub.status.idle":"2023-06-23T04:20:00.509968Z","shell.execute_reply.started":"2023-06-23T04:20:00.148127Z","shell.execute_reply":"2023-06-23T04:20:00.508875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing","metadata":{}},{"cell_type":"code","source":"train_ds_mapped = train_ds.map(load_and_preprocess_image)\nval_ds_mapped = val_ds.map(load_and_preprocess_image)\ntest_ds_mapped = test_ds.map(load_and_preprocess_image)\n\ntrain_ds_mapped.prefetch(tf.data.AUTOTUNE)\nval_ds_mapped.prefetch(tf.data.AUTOTUNE)\ntest_ds_mapped.prefetch(tf.data.AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2023-06-23T04:20:00.511142Z","iopub.execute_input":"2023-06-23T04:20:00.511487Z","iopub.status.idle":"2023-06-23T04:20:00.623458Z","shell.execute_reply.started":"2023-06-23T04:20:00.511457Z","shell.execute_reply":"2023-06-23T04:20:00.622307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Visualization","metadata":{}},{"cell_type":"code","source":"# Calculate class distribution\nclass_dis = [len(os.listdir(train_dir + name)) for name in class_names]\n# class_dis = [len(os.listdir(val_dir + name)) for name in class_names]\n# class_dis = [len(os.listdir(test_dir + name)) for name in class_names]\n\n# Visualize using interactive pie chart\npie_chart = px.pie(values=class_dis, names=class_names, color=class_names)\npie_chart.update_layout({'title':{'text':\"Class Distribution\"}})\npie_chart.show()\n\n# Visualize using interactive bar chart\nbar_chart = px.bar(y=class_dis, x=class_names, color=class_names)\nbar_chart.show()","metadata":{"execution":{"iopub.status.busy":"2023-06-23T04:20:00.624907Z","iopub.execute_input":"2023-06-23T04:20:00.625627Z","iopub.status.idle":"2023-06-23T04:20:02.061307Z","shell.execute_reply.started":"2023-06-23T04:20:00.625595Z","shell.execute_reply":"2023-06-23T04:20:02.060292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_images(train_ds)","metadata":{"execution":{"iopub.status.busy":"2023-06-23T04:20:02.062855Z","iopub.execute_input":"2023-06-23T04:20:02.063293Z","iopub.status.idle":"2023-06-23T04:20:03.473291Z","shell.execute_reply.started":"2023-06-23T04:20:02.063266Z","shell.execute_reply":"2023-06-23T04:20:03.472204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_images(train_ds_mapped)","metadata":{"execution":{"iopub.status.busy":"2023-06-23T04:20:03.474438Z","iopub.execute_input":"2023-06-23T04:20:03.474756Z","iopub.status.idle":"2023-06-23T04:20:05.625722Z","shell.execute_reply.started":"2023-06-23T04:20:03.474728Z","shell.execute_reply":"2023-06-23T04:20:05.624662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Building","metadata":{}},{"cell_type":"code","source":"# Download inception\n\ninception_no_train = InceptionV3(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), weights='imagenet', include_top=False)\ninception_no_train.trainable = False\n\ninception_half_train = InceptionV3(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), weights='imagenet', include_top=False)\ninception_half_train.trainable = True\n\ninception_full_train = InceptionV3(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), weights='imagenet', include_top=False)\ninception_full_train.trainable = True","metadata":{"execution":{"iopub.status.busy":"2023-06-23T04:24:50.439762Z","iopub.execute_input":"2023-06-23T04:24:50.440088Z","iopub.status.idle":"2023-06-23T04:24:59.733794Z","shell.execute_reply.started":"2023-06-23T04:24:50.440061Z","shell.execute_reply":"2023-06-23T04:24:59.733127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# half freeze\nnum_layers = len(inception_half_train.layers) // 2\nnum_layers\nfor i in range(num_layers):\n    inception_half_train.layers[i].trainable = False","metadata":{"execution":{"iopub.status.busy":"2023-06-23T04:24:59.735135Z","iopub.execute_input":"2023-06-23T04:24:59.735791Z","iopub.status.idle":"2023-06-23T04:24:59.792805Z","shell.execute_reply.started":"2023-06-23T04:24:59.735768Z","shell.execute_reply":"2023-06-23T04:24:59.791904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Summary","metadata":{}},{"cell_type":"code","source":"# full freeze\nname = 'aksara_jawa_inception_full_freeze_v1'\n\ninception_transferred_full = Sequential([\n    inception_no_train,\n    GlobalAveragePooling2D(),\n    \n    # 1 layer\n    Dropout(0.5),\n    \n    Dense(1024, activation='relu'),\n    # 2 layer\n    Dropout(0.25),\n    \n    Dense(n_classes, activation='softmax')\n], name=name)\n\ninception_transferred_full.compile(\n    loss=LOSS,\n    optimizer=Adam(learning_rate=LEARNING_RATE),\n#     optimizer=SGD(learning_rate=LEARNING_RATE),\n    metrics=METRICS\n)\n\ninception_transferred_full.summary()\nprint('\\n\\n\\n', '*'*90)\n\n\n# half\nname = 'aksara_jawa_inception_half_freeze_v1'\n\ninception_transferred_half = Sequential([\n    inception_half_train,\n    GlobalAveragePooling2D(),\n    \n    # 1 layer\n    Dropout(0.5),\n    \n    Dense(1024, activation='relu'),\n    # 2 layer\n    Dropout(0.25),\n    \n    Dense(n_classes, activation='softmax')\n], name=name)\n\ninception_transferred_half.compile(\n    loss=LOSS,\n    optimizer=Adam(learning_rate=LEARNING_RATE),\n#     optimizer=SGD(learning_rate=LEARNING_RATE),\n    metrics=METRICS\n)\n\ninception_transferred_half.summary()\nprint('\\n\\n\\n', '*'*90)\n\n\n# no freeze\nname = 'aksara_jawa_inception_no_freeze_v1'\n\ninception_transferred_no = Sequential([\n    inception_full_train,\n    GlobalAveragePooling2D(),\n    \n    # 1 layer\n    Dropout(0.5),\n    \n    Dense(1024, activation='relu'),\n    # 2 layer\n    Dropout(0.25),\n    \n    Dense(n_classes, activation='softmax')\n], name=name)\n\ninception_transferred_no.compile(\n    loss=LOSS,\n    optimizer=Adam(learning_rate=LEARNING_RATE),\n#     optimizer=SGD(learning_rate=LEARNING_RATE),\n    metrics=METRICS\n)\n\ninception_transferred_no.summary()","metadata":{"execution":{"iopub.status.busy":"2023-06-23T04:24:59.794406Z","iopub.execute_input":"2023-06-23T04:24:59.794951Z","iopub.status.idle":"2023-06-23T04:25:01.682856Z","shell.execute_reply.started":"2023-06-23T04:24:59.794928Z","shell.execute_reply":"2023-06-23T04:25:01.682057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Full Freeze","metadata":{}},{"cell_type":"code","source":"print(f\"\\nTraining {inception_transferred_full.name}: \")\n\ncsv_file = f'{inception_transferred_full.name}.csv'\n\ntime = timer(None)\nhistory_full = inception_transferred_full.fit(\n    train_ds_mapped, \n    validation_data=val_ds_mapped, \n    epochs=EPOCHS,\n    callbacks=[\n        EarlyStopping(patience=EARLYSTOP_PATIENCE, restore_best_weights=True),\n        ModelCheckpoint(f\"checkpoint-{inception_transferred_full.name}.h5\", save_best_only=True),\n        CSVLogger(csv_file)\n    ],\n    batch_size=BATCH_SIZE,\n)\ntime_taken = timer(time)\nprint(time_taken)","metadata":{"execution":{"iopub.status.busy":"2023-06-23T04:25:01.684368Z","iopub.execute_input":"2023-06-23T04:25:01.685223Z","iopub.status.idle":"2023-06-23T04:25:35.891828Z","shell.execute_reply.started":"2023-06-23T04:25:01.685200Z","shell.execute_reply":"2023-06-23T04:25:35.890572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Half Freeze","metadata":{}},{"cell_type":"code","source":"print(f\"\\nTraining {inception_transferred_half.name}: \")\n\ncsv_file = f'{inception_transferred_half.name}.csv'\n\ntime = timer(None)\nhistory_half = inception_transferred_half.fit(\n    train_ds_mapped, \n    validation_data=val_ds_mapped, \n    epochs=EPOCHS,\n    callbacks=[\n        EarlyStopping(patience=EARLYSTOP_PATIENCE, restore_best_weights=True),\n        ModelCheckpoint(f\"checkpoint-{inception_transferred_half.name}.h5\", save_best_only=True),\n        CSVLogger(csv_file)\n    ],\n    batch_size=BATCH_SIZE,\n)\ntime_taken = timer(time)\nprint(time_taken)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train No Freeze","metadata":{}},{"cell_type":"code","source":"print(f\"\\nTraining {inception_transferred_no.name}: \")\n\ncsv_file = f'{inception_transferred_no.name}.csv'\n\ntime = timer(None)\nhistory_no = inception_transferred_no.fit(\n    train_ds_mapped, \n    validation_data=val_ds_mapped, \n    epochs=EPOCHS,\n    callbacks=[\n        EarlyStopping(patience=EARLYSTOP_PATIENCE, restore_best_weights=True),\n        ModelCheckpoint(f\"checkpoint-{inception_transferred_no.name}.h5\", save_best_only=True),\n        CSVLogger(csv_file)\n    ],\n    batch_size=BATCH_SIZE,\n)\ntime_taken = timer(time)\nprint(time_taken)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluate","metadata":{}},{"cell_type":"code","source":"print('\\nfull freeze')\ntest_loss_f, test_acc_f = inception_transferred_full.evaluate(test_ds_mapped)\nprint(\"Loss    : {:.4}\".format(test_loss_f))\nprint(\"Accuracy: {:.4}%\".format(test_acc_f*100))\n\nprint('\\nhalf freeze')\ntest_loss_h, test_acc_h = inception_transferred_half.evaluate(test_ds_mapped)\nprint(\"Loss    : {:.4}\".format(test_loss_h))\nprint(\"Accuracy: {:.4}%\".format(test_acc_h*100))\n\nprint('\\nno freeze')\ntest_loss_n, test_acc_n = inception_transferred_no.evaluate(test_ds_mapped)\nprint(\"Loss    : {:.4}\".format(test_loss_n))\nprint(\"Accuracy: {:.4}%\".format(test_acc_n*100))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Graph","metadata":{}},{"cell_type":"code","source":"plot_history(history_full, test_loss_f, test_acc_f, 'Inception Full')\nplot_history(history_half, test_loss_h, test_acc_h, 'Inception Half')\nplot_history(history_no, test_loss_n, test_acc_n, 'Inception No')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Confusion Matrix","metadata":{}},{"cell_type":"code","source":"y_f, y_h, y_n, = [], [], []  # store predicted labels\ny_true = []  # store true labels\n\n# iterate over the dataset\nfor image_batch, label_batch in test_ds_mapped:   # use dataset.unbatch() with repeat\n    # append true labels\n    y_true.append(label_batch)\n    # compute predictions\n    preds_f = inception_transferred_full.predict(image_batch, verbose=0)\n    preds_h = inception_transferred_half.predict(image_batch, verbose=0)\n    preds_n = inception_transferred_no.predict(image_batch, verbose=0)\n    # append predicted labels\n    y_f.append(np.argmax(preds_f, axis = - 1))\n    y_h.append(np.argmax(preds_h, axis = - 1))\n    y_n.append(np.argmax(preds_n, axis = - 1))\n\n# convert the true and predicted labels into tensors\ncorrect_labels = tf.concat([item for item in y_true], axis = 0)\npredicted_labels_f = tf.concat([item for item in y_f], axis = 0)\npredicted_labels_h = tf.concat([item for item in y_h], axis = 0)\npredicted_labels_n = tf.concat([item for item in y_n], axis = 0)\n\ncls()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('\\nfull freeze')\nplot_confusion_m(correct_labels, predicted_labels_f, class_names)\n\nprint('\\nhalf freeze')\nplot_confusion_m(correct_labels, predicted_labels_h, class_names)\n\nprint('\\nno freeze')\nplot_confusion_m(correct_labels, predicted_labels_n, class_names)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prediction Visualization","metadata":{}},{"cell_type":"code","source":"plot_images(test_ds_mapped, model=inception_transferred_full, n_rows=5)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_images(test_ds_mapped, model=inception_transferred_half, n_rows=5)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_images(test_ds_mapped, model=inception_transferred_no, n_rows=5)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CSV Preview","metadata":{}},{"cell_type":"code","source":"pd.read_csv(f'{inception_transferred_full.name}.csv').head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.read_csv(f'{inception_transferred_half.name}.csv').head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.read_csv(f'{inception_transferred_no.name}.csv').head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save Model","metadata":{}},{"cell_type":"code","source":"inception_transferred_full.save(inception_transferred_full.name+'.h5')\ninception_transferred_half.save(inception_transferred_half.name+'.h5')\ninception_transferred_no.save(inception_transferred_no.name+'.h5')","metadata":{},"execution_count":null,"outputs":[]}],"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}}